{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7521c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74d7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cbba8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input for base learners\n",
    "def prepare_input(X_q):\n",
    "    \"\"\"This function preprocess the data and construct the input features for base learners \n",
    "    using trained scaler for numerical features and one hot encoder for categorical features \"\"\"\n",
    "    \n",
    "    # define the categorical & numerical features which are taken for training the model\n",
    "    cat_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "    num_features = ['age', 'duration', 'campaign', 'pdays', 'previous', 'cons.price.idx', 'cons.conf.idx', 'nr.employed']\n",
    "    \n",
    "    # load standard scaler from pickle file\n",
    "    scaler = joblib.load('num_features_scaler.pkl')\n",
    "    # load trained onehotencoder for categorical features\n",
    "    cat_features_ohe = joblib.load('cat_features_ohe.pkl')\n",
    "    \n",
    "    # tranform the numerical features with trained standard scaler and convert it into a dataframe for further use\n",
    "    X_q_num = pd.DataFrame(scaler.transform(X_q[num_features]), columns=num_features)\n",
    "    # print(X_q_num, type(X_q_num))\n",
    "    \n",
    "    # tranform the categorical features with trained onehotencoder and convert it into a dataframe for further use\n",
    "    X_q_ohe = cat_features_ohe.transform(X_q[cat_features])\n",
    "    # print(X_q_ohe)\n",
    "    cat_feature_labels_ohe = np.concatenate(cat_features_ohe.categories_).ravel().tolist()\n",
    "    X_q_ohe = pd.DataFrame(X_q_ohe.toarray(), columns=cat_feature_labels_ohe)\n",
    "    # print(type(X_q_ohe), type(X_q_num))\n",
    "    \n",
    "    # merge both numerical feature set and categorical feature set\n",
    "    X_q_final = pd.concat([X_q_ohe, X_q_num], axis=1)\n",
    "    \n",
    "    # print(X_q_final)\n",
    "    return X_q_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "def final_predict(X_q, y=''):\n",
    "    \"\"\"This function predcts target label for query instance, the prediction is from trained meta model \"\"\"    \n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # get the form inputs through request\n",
    "    form_inputs = request.form.to_dict()\n",
    "    print(form_inputs)\n",
    "    \n",
    "    return True\n",
    "    \n",
    "    # data pre processing and prepare the input to predict through meta model\n",
    "    X_input = prepare_input(X_q)\n",
    "    \n",
    "    # load the trained base models from pickle file\n",
    "    base_models = joblib.load('base_learners.pkl')\n",
    "    # print(base_models)\n",
    "    \n",
    "    # initiate list for storing the predictions from each base learner for given query point\n",
    "    input_for_meta = []\n",
    "    # predictions from base learners\n",
    "    for model in base_models:\n",
    "        input_for_meta.append(model.predict(X_input))\n",
    "        \n",
    "    # construct the input to meta model from base learners predictions\n",
    "    input_for_meta = np.transpose(np.asarray(input_for_meta))\n",
    "    # load trained meta model from pickle file \n",
    "    meta_model = joblib.load('meta_model.pkl')\n",
    "    # final prediction\n",
    "    final_prediction = meta_model.predict(input_for_meta)\n",
    "    \n",
    "    # print(final_prediction)\n",
    "    if final_prediction:\n",
    "        prediction = 'Positive'\n",
    "    else:\n",
    "        prediction = 'Negative'\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # computing the time taken for predicting the target label\n",
    "    time_for_prediction = str(end_time - start_time) + ' seconds'\n",
    "    \n",
    "    # handling true label\n",
    "    y = 'Positive' if y==1 else 'Negative'\n",
    "    \n",
    "    response = jsonify({'prediction': prediction, 'True label': y, 'Time taken for Prediction': time_for_prediction})\n",
    "    # return predicted label, time taken for predicting and the original target label if passed as input\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c564bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/index')\n",
    "def index():\n",
    "    return flask.render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b76da3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def welcome():\n",
    "    return 'Welcome to the Lead Score Prediction home page'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b358c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace79915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
